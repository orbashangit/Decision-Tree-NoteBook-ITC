{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-11T21:26:06.748437Z",
     "end_time": "2023-11-11T21:26:06.764059Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `calculate_entropy` Function explained in detail\n",
    "computes the entropy of a set of labels.\n",
    "1. **Input**:\n",
    "   - It takes a set of labels (`y`) as input.\n",
    "\n",
    "2. **Unique Labels and Counts**:\n",
    "   - It identifies the unique labels present in the input along with their respective counts using `np.unique(y, return_counts=True)`.\n",
    "\n",
    "3. **Probability Calculation**:\n",
    "   - For each unique label, it calculates the probability by dividing the count of each label by the total number of labels in the input.\n",
    "\n",
    "4. **Entropy Calculation**:\n",
    "   - Utilizing the probabilities of the labels, it computes the entropy using the standard entropy formula: \\( -\\sum_{i} p_i \\log_2(p_i) \\), where \\(p_i\\) represents the probability of each unique label.\n",
    "\n",
    "5. **Return**:\n",
    "   - The function returns the computed entropy value.\n",
    "\n",
    "This function is crucial in the decision tree algorithm as it's used to determine the impurity or disorder in a set of labels, a key factor in deciding how to split the data effectively at each node of the tree. The lower the entropy, the more homogenous the set of labels, making it a potential stopping point in the tree's growth."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-11T21:26:08.783801Z",
     "end_time": "2023-11-11T21:26:08.799433Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\"\n",
    "    Calculate the entropy of a set of labels.\n",
    "\n",
    "    Args:\n",
    "        y (array-like): Target variable labels.\n",
    "\n",
    "    Returns:\n",
    "        float: Entropy value.\n",
    "    \"\"\"\n",
    "    unique_labels, label_counts = np.unique(y, return_counts=True)\n",
    "    probabilities = label_counts / len(y)\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    ":\n",
    "## find_best_split Function explained in detail\n",
    "1. **Initialization**:\n",
    "   - `best_feature`, `best_value`, and `best_information_gain` are initialized to None and -1 respectively. These variables will hold the best split found and the information gain achieved.\n",
    "\n",
    "2. **Calculate Current Entropy**:\n",
    "   - The current entropy for the provided subset of data (`node_indices`) is calculated using the `calculate_entropy` function.\n",
    "\n",
    "3. **Iterating through Features**:\n",
    "   - It loops through each feature in the dataset.\n",
    "\n",
    "4. **Iterating through Unique Values of the Feature**:\n",
    "   - For each feature, it identifies unique values in that feature within the provided subset.\n",
    "\n",
    "5. **Splitting the Data**:\n",
    "   - For each value of the feature, it splits the dataset into two groups - left and right - based on whether the feature value is less than or greater than the selected value.\n",
    "\n",
    "6. **Entropy Calculation**:\n",
    "   - It calculates the entropy for both the left and right subsets.\n",
    "\n",
    "7. **Information Gain Calculation**:\n",
    "   - Using the entropy of the subsets, it calculates the information gain by considering how much each split reduces the entropy in comparison to the starting entropy of the whole dataset.\n",
    "\n",
    "8. **Update Best Split**:\n",
    "   - If the information gain from the current split is higher than the previous best information gain, it updates the `best_information_gain`, `best_feature`, and `best_value`.\n",
    "\n",
    "9. **Return Best Split**:\n",
    "   - Finally, it returns the best feature and value found, which represent the optimal way to split the data to maximize information gain.\n",
    "\n",
    "This function essentially searches for the best feature and value combination to split the data, aiming to maximize the information gain, a crucial step in building a decision tree.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "def find_best_split(X, y, node_indices):\n",
    "    \"\"\"\n",
    "    Find the best feature and value to split the dataset based on information gain.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray): Data matrix of shape (n_samples, n_features).\n",
    "        y (array-like): Target variable labels.\n",
    "        node_indices (ndarray): List containing the active indices.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Best feature index, best split value.\n",
    "    \"\"\"\n",
    "    best_feature = None\n",
    "    best_value = None\n",
    "    best_information_gain = -1\n",
    "\n",
    "    current_entropy = calculate_entropy(y[node_indices])\n",
    "\n",
    "    for feature_index in range(X.shape[1]):\n",
    "        unique_values = np.unique(X[node_indices, feature_index])\n",
    "\n",
    "        for value in unique_values:\n",
    "            left_indices = node_indices[X[node_indices, feature_index] <= value]\n",
    "            right_indices = node_indices[X[node_indices, feature_index] > value]\n",
    "\n",
    "            if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                continue\n",
    "\n",
    "            left_entropy = calculate_entropy(y[left_indices])\n",
    "            right_entropy = calculate_entropy(y[right_indices])\n",
    "\n",
    "            information_gain = current_entropy - (\n",
    "                    len(left_indices) / len(node_indices) * left_entropy +\n",
    "                    len(right_indices) / len(node_indices) * right_entropy\n",
    "            )\n",
    "\n",
    "            if information_gain > best_information_gain:\n",
    "                best_information_gain = information_gain\n",
    "                best_feature = feature_index\n",
    "                best_value = value\n",
    "\n",
    "    return best_feature, best_value\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-11T21:26:12.857817Z",
     "end_time": "2023-11-11T21:26:12.873470Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## build_tree_recursive Function explained in detail\n",
    "\n",
    "1. **Input**:\n",
    "   - It takes several parameters:\n",
    "     - `X`: Data matrix of shape (n_samples, n_features).\n",
    "     - `y`: List or array containing the target variable.\n",
    "     - `node_indices`: List containing the active indices, i.e., the samples considered in this step.\n",
    "     - `branch_name`: Name of the branch in the tree (e.g., 'Root', 'Left', 'Right').\n",
    "     - `max_depth`: Maximum depth of the resulting tree.\n",
    "     - `current_depth`: The current depth in the recursive process.\n",
    "\n",
    "2. **Printing Node Information**:\n",
    "   - It prints information about the current node such as the branch name, current depth, number of samples at the node, and the distribution of classes in those samples.\n",
    "\n",
    "3. **Stopping Conditions**:\n",
    "   - It checks stopping conditions:\n",
    "     - If the current depth equals the maximum depth or if there's only one unique label in the node, it returns, indicating the end of that branch.\n",
    "     - This establishes a limit on the depth of the tree or if a pure node (only one class) is reached.\n",
    "\n",
    "4. **Finding Best Split**:\n",
    "   - It calls the `find_best_split` function to identify the best feature and value to split the data further.\n",
    "\n",
    "5. **Splitting Data**:\n",
    "   - If a valid split is found, it divides the data into left and right subsets based on the best feature and value.\n",
    "\n",
    "6. **Recursive Calls**:\n",
    "   - It recursively calls itself for the left and right subsets, incrementing the depth for each call until a stopping condition is met.\n",
    "\n",
    "This function essentially constructs the decision tree structure by identifying the best splits and branching into subsequent nodes, building the tree in a recursive manner until the stopping conditions are met. The printed information aids in visualizing the structure of the tree and understanding the splits being made at each level."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
    "    \"\"\"\n",
    "    Build a tree using the recursive algorithm that splits the dataset into 2 subgroups at each node.\n",
    "    This function just prints the tree.\n",
    "\n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape (n_samples, n_features).\n",
    "        y (array-like):         List or ndarray with n_samples containing the target variable.\n",
    "        node_indices (ndarray): List containing the active indices, i.e., the samples being considered in this step.\n",
    "        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right'].\n",
    "        max_depth (int):        Max depth of the resulting tree.\n",
    "        current_depth (int):    Current depth. Parameter used during recursive call.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(y[node_indices])\n",
    "    print(f\"{branch_name} Depth: {current_depth}, Samples: {len(node_indices)}, Class Distribution: {dict(zip(unique_labels, np.bincount(y[node_indices])))}\")\n",
    "\n",
    "    if current_depth == max_depth or len(unique_labels) == 1:\n",
    "        return\n",
    "\n",
    "    best_feature, best_value = find_best_split(X, y, node_indices)\n",
    "\n",
    "    if best_feature is not None:\n",
    "        print(f\"{branch_name} Splitting at Feature {best_feature} with Value {best_value}\")\n",
    "        left_indices = node_indices[X[node_indices, best_feature] <= best_value]\n",
    "        right_indices = node_indices[X[node_indices, best_feature] > best_value]\n",
    "\n",
    "        build_tree_recursive(X, y, left_indices, branch_name=\"Left\", max_depth=max_depth, current_depth=current_depth + 1)\n",
    "        build_tree_recursive(X, y, right_indices, branch_name=\"Right\", max_depth=max_depth, current_depth=current_depth + 1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-11T21:26:15.979025Z",
     "end_time": "2023-11-11T21:26:15.994560Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You will start by loading the dataset for this task. The dataset you have collected is as follows:\n",
    "\n",
    "| glasses | Tall | Long hair | man/woman(0/1) |\n",
    "|:-------:|:----:|:---------:|:--------------:|\n",
    "|    1    |  1   |     1     |       1        |\n",
    "|    0    |  0   |     1     |       1        |\n",
    "|    1    |  0   |     0     |       0        |\n",
    "|    1    |  0   |     0     |       0        |\n",
    "|    0    |  0   |     1     |       1        |\n",
    "|    1    |  1   |     1     |       0        |\n",
    "|    1    |  0   |     0     |       0        |\n",
    "|    0    |  1   |     1     |       1        |\n",
    "|    0    |  1   |     1     |       1        |\n",
    "|    0    |  1   |     1     |       0        |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "   glasses  Tall  Long_hair  man_woman\n",
      "0        1     1          1          1\n",
      "1        0     0          1          1\n",
      "2        1     0          0          0\n",
      "3        1     0          0          0\n",
      "4        0     0          1          1\n",
      "5        1     1          1          0\n",
      "6        1     0          0          0\n",
      "7        0     1          1          1\n",
      "8        0     1          1          1\n",
      "9        0     1          1          0\n",
      "\n",
      "\n",
      "Root Depth: 0, Samples: 10, Class Distribution: {0: 5, 1: 5}\n",
      "Root Splitting at Feature 2 with Value 0\n",
      "Left Depth: 1, Samples: 3, Class Distribution: {0: 3}\n",
      "Right Depth: 1, Samples: 7, Class Distribution: {0: 2, 1: 5}\n",
      "Right Splitting at Feature 1 with Value 0\n",
      "Left Depth: 2, Samples: 2, Class Distribution: {1: 0}\n",
      "Right Depth: 2, Samples: 5, Class Distribution: {0: 2, 1: 3}\n",
      "Right Splitting at Feature 0 with Value 0\n",
      "Left Depth: 3, Samples: 3, Class Distribution: {0: 1, 1: 2}\n",
      "Right Depth: 3, Samples: 2, Class Distribution: {0: 1, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from the provided data\n",
    "data = {\n",
    "    'glasses': [1, 0, 1, 1, 0, 1, 1, 0, 0, 0],\n",
    "    'Tall': [1, 0, 0, 0, 0, 1, 0, 1, 1, 1],\n",
    "    'Long_hair': [1, 1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
    "    'man_woman': [1, 1, 0, 0, 1, 0, 0, 1, 1, 0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Original Dataset:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Convert DataFrame to NumPy arrays\n",
    "X = df[['glasses', 'Tall', 'Long_hair']].values\n",
    "y = df['man_woman'].values\n",
    "\n",
    "# Run the build_tree_recursive function on the dataset\n",
    "build_tree_recursive(X, y, node_indices=np.arange(len(y)), branch_name=\"Root\", max_depth=3, current_depth=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-11T21:26:18.241429Z",
     "end_time": "2023-11-11T21:26:18.257061Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-10T14:17:27.418581Z",
     "end_time": "2023-11-10T14:17:27.435996Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
